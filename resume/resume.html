<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Collins Westnedge — Resume (Short)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <style>
  body {
    max-width: 700px;
    margin: 40px auto;
    padding: 0 20px;
    line-height: 1.6;
  }
  
  h1 {
    font-size: 18pt;
    text-align: center;
    letter-spacing: 4px;
    margin-bottom: 20px;
  }
  
  h2 {
    font-size: 12pt;
    border-top: 2px solid black;
    border-bottom: 1px solid black;
    padding: 4px 0;
    margin: 20px 0 10px;
    letter-spacing: 2px;
  }
  
  a {
    color: black;
  }
  
  ul {
    margin-left: 30px;
  }
  
  .header-info {
    text-align: center;
    margin-bottom: 20px;
  }
</style>

</head>
<body>

<h1>COLLINS WESTNEDGE</h1>
<div class="header-info">
  Chicago, IL &nbsp;|&nbsp;
  <a href="mailto:cwestnedge@gmail.com">cwestnedge@gmail.com</a> &nbsp;|&nbsp;
  <a href="https://www.linkedin.com/in/collins-westnedge/">LinkedIn</a> &nbsp;|&nbsp;
  <a href="https://donkeyanaphora.github.io">Website</a> &nbsp;|&nbsp;
  <a href="https://github.com/donkeyanaphora">GitHub</a> &nbsp;|&nbsp;
  <a href="https://huggingface.co/cwestnedge">Hugging Face</a>
</div>

<h2>SKILLS</h2>
<p><strong>Programming:</strong> Python (PyTorch, Transformers, NumPy, pandas, scikit-learn), SQL, Git</p>
<p><strong>LLM/NLP:</strong> RAG, prompt engineering, fine-tuning (mixed precision, grad accumulation), shallow fusion for ASR, activation steering, debiasing, contrastive learning</p>
<p><strong>MLOps &amp; Data:</strong> Experiment design &amp; permutation tests, calibration, distributed training, MLflow, Databricks/Spark, Azure (Cognitive Search, Document Intelligence), Kubernetes, Hugging Face Hub</p>

<h2>EXPERIENCE</h2>
<div class="position">
  <span class="company">Northwestern Mutual</span> — Data Science &amp; Analytics<br />
  <span class="role">Senior Data Scientist (2022–Present) &nbsp;|&nbsp; Data Scientist (2021–2022)</span>
</div>
<ul>
  <li><strong>Led data-science efforts</strong> for a CSR-facing RAG platform (with a senior engineer); designed & implemented automated evaluation reducing A/B cycles from ~30 days to <strong>7 minutes</strong>; adopted across CSR org (~700 users)</li>  
  <li><strong>Engineered</strong> an ASR pipeline that cut projected annual run-rate from <strong>~$2M to ~$100K (~95%)</strong></li>
  <li><strong>Delivered</strong> a multi-stage LLM workflow for regulatory checks (risk tolerance &amp; consent) with human-in-the-loop validation; <strong>saved 250+ hours annually</strong> while meeting audit requirements</li>
  <li><strong>Sponsored &amp; advised</strong> InfoNCE fine-tuning (contrastive + domain adaptation); project owner achieved a <strong>70%</strong> reduction in vector storage</li>
</ul>

<div class="position">
  <span class="company">Northwestern Mutual Data Science Institute</span> — Research Subcommittee Member (2023–Present)
</div>
<ul>
  <li><strong>Reviewed &amp; advised</strong> ML/AI grants, guided experimental design and evaluation, and delivered workshops and panel discussions on ML/AI</li>
</ul>

<div class="position">
  <span class="company">Hanover Investment Advisors</span> — Statistical Programming Analyst (2014–2017)
</div>
<ul>
  <li><strong>Analyzed</strong> commercial real-estate datasets to inform portfolio allocation and risk modeling for institutional clients</li>
</ul>

<h2>SELECTED PROJECTS</h2>
<div class="position">
  <span class="company">Medical Speech Recognition via Shallow Fusion</span> — <a href="https://github.com/donkeyanaphora/SHALLOW_FUSION">GitHub</a>
</div>
<ul>
  <li><strong>Implemented</strong> shallow fusion integrating Whisper ASR with domain-adapted GPT-2 via a custom LogitsProcessor; achieved an <strong>8.5% relative WER reduction</strong> (p = 0.024) on medical speech using beam-search integration</li>
  <li><strong>Built</strong> an evaluation framework with medical terminology normalization, permutation-based significance testing, and domain-specific error analysis; released models and complete implementation</li>
</ul>

<div class="position">
  <span class="company">GPT-2 Domain Adaptation</span> — <a href="https://huggingface.co/cwestnedge">Hugging Face</a>
</div>
<ul>
  <li><strong>Fine-tuned</strong> GPT-2 on 3.6B PubMed tokens using a production-grade training pipeline with mixed precision (FP16), gradient accumulation (128 effective batch size), and fault-tolerant checkpointing</li>
  <li><strong>Implemented</strong> training optimizations including cosine scheduling with linear warmup, selective weight decay capability, and automatic checkpoint recovery; achieved stable convergence at 131K tokens/batch</li>
</ul>

<div class="position">
  <span class="company">IR Concept Erasure</span> — <a href="https://github.com/donkeyanaphora/IR_CONCEPT_ERASURE">GitHub</a>
</div>
<ul>
  <li><strong>Developed</strong> a debiasing method using projection-based concept removal in embedding spaces; <strong>42% reduction</strong> in bias triggers while maintaining 98% retrieval quality</li>
</ul>

<h2>EDUCATION</h2>
<div class="position">
  <span class="company">University of Chicago</span> — B.A., Philosophy (2018)<br />
  <span class="role">Relevant coursework: Logic; Probability and Statistics; Dynamic Semantics</span>
</div>

<div class="position">
  <span class="company">University of Wisconsin–Milwaukee</span> — Mathematics Coursework (2024–Present)<br />
  <span class="role">Completed: Linear Algebra; In progress: Calculus III</span>
</div>

</body>
</html>