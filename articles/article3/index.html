<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Extra-Ordinary Language - Collins Westnedge</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no, viewport-fit=cover">
  
  <!-- Mobile app settings -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- SEO essentials -->
  <meta name="google-site-verification" content="hmW81pKLkPLJXY0kFe-I1vNXno-xD9XbEWyZyGfz-SA" />
  <meta name="description" content="An exploration of literary and
creative intelligence and things I wish language models did better.">
  <meta name="author" content="Collins Westnedge">
  <link rel="canonical" href="https://donkeyanaphora.github.io/articles/article3/">
  
  <!-- Hide drafts from search engines -->
  

  <!-- Site look & feel -->
  <link rel="stylesheet" href="../../assets/css/main.css"/>
  <link rel="stylesheet" href="../../assets/css/article.css"/>
  
  <!-- Favicons -->
  <link rel="apple-touch-icon" sizes="180x180" href="../../favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="../../favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../../favicon/favicon-16x16.png">
  <link rel="manifest" href="../../favicon/site.webmanifest">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://donkeyanaphora.github.io/articles/article3/">
  <meta property="og:title" content="Extra-Ordinary Language">
  <meta property="og:description" content="An exploration of literary
and creative intelligence and things I wish language models did
better.">
  <meta property="og:image" content="https://donkeyanaphora.github.io/assets/images/thumbnail.png">
  <meta property="og:site_name" content="The Latent Realm">
  <meta property="article:author" content="Collins Westnedge">
  <meta property="article:published_time" content="2025-07-02">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:url" content="https://donkeyanaphora.github.io/articles/article3/">
  <meta name="twitter:title" content="Extra-Ordinary Language">
  <meta name="twitter:description" content="An exploration of literary
and creative intelligence and things I wish language models did
better.">
  <meta name="twitter:image" content="https://donkeyanaphora.github.io/assets/images/thumbnail.png">

  <!-- MathJax config -->
  <!-- <script>
    window.MathJax = {
      tex:   { displayIndent: '0em',  displayAlign: 'center' },
      chtml: { mtextFont: 'Times' }
    };
  </script> -->
  
  <script>
    window.MathJax = {
      tex: {},  // Empty is fine
      chtml: { 
        mtextFont: 'Times',
        displayAlign: 'center',    // ✅ Moved here
        displayIndent: '0em'       // ✅ Moved here
      }
    };
  </script>
  <!-- MathJax -->
  <script defer id="MathJax-script"
          src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js">
  </script>
</head>

<body class="article">
  <!-- floating buttons -->
  <button id="menuBtn" class="float-btn" aria-label="Open menu">🧰</button>
  <button class="float-btn back-btn" onclick="window.location.href='../../'" aria-label="Back to home">🏡</button>
  <button id="toggleDark" class="float-btn" aria-label="Toggle dark mode">🌙</button>

  <!-- Markdown content -->
  <main class="content">
    <article class="markdown-body">
      <h1 id="extra-ordinary-language">🎭 Extra-Ordinary Language</h1>
      <p><strong>COLLINS WESTNEDGE</strong><br />
      <em>JULY 2, 2025</em></p>
      <h2 id="introduction">Introduction</h2>
      <p>I’ve been thinking about a conversation I had with a former
      colleague about language that defies ordinary usage. More
      specifically expressions that violate the <a
      href="https://en.wikipedia.org/wiki/Distributional_semantics">distributional
      hypothesis</a> of language and yet carry high degrees of
      intentionality and depth.</p>
      <p>When Kafka wrote “A cage went in search of a bird,” he created
      something that on the surface seems impossible and yet expresses a
      profound and insidious truth. Current AI systems, for all their
      linguistic sophistication, rarely produce such language. They
      excel at coherent, informative prose but struggle with the kind of
      intentional violations that define great literature.</p>
      <p>In this post, I’m dog-earing these thoughts to revisit later.
      The aim here is to understand what makes these expressions work
      and more critically, the implications this has on how we measure
      and evaluate model intelligence.</p>
      <!-- Along the way, I'll attempt some preliminary formalizations and speculate about why current AI systems struggle with this capacity. -->
      <h2 id="literary-examples">Literary Examples</h2>
      <blockquote>
      <p>So they lov’d, as love in twain<br />
      Had the essence but in one;<br />
      Two distincts, division none:<br />
      Number there in love was slain.</p>
      <p>Hearts remote, yet not asunder;<br />
      Distance and no space was seen<br />
      Twixt this Turtle and his queen</p>
      <p>— <em>Shakespeare, <strong>The Phoenix and the
      Turtle</strong></em></p>
      </blockquote>
      <blockquote>
      <p>A cage went in search of a bird.</p>
      <p>— <em>Kafka, <strong>Aphorisms</strong></em>
      <!-- > I can't go on. I'll go on.

      - *Beckett, **The The Unnamable** --> Merry and tragical! Tedious
      and brief!<br />
      That is, hot ice and wondrous strange snow.<br />
      How shall we find the concord of this discord?</p>
      <p>— <em>Shakespeare, <strong>A Midsummer Night’s
      Dream</strong></em></p>
      </blockquote>
      <h2 id="pseudo-formalizations">Pseudo Formalizations</h2>
      <p>Because of their intentionality and depth I’m going to call
      these violations of “ordinary use” <strong>extra-ordinary
      use</strong>. They don’t obscure meaning but instead elucidate by
      way of contradiction or a violation of expectations. To explore
      how these linguistic violations work, I’ll borrow notation from
      formal logic. This isn’t meant as rigorous formalization, but
      rather as tool to highlight the syntactic and semantic patterns
      that make these expressions interesting.</p>
      <h3 id="two-models-of-interpretation">Two Models of
      Interpretation</h3>
      <p>First, it’s helpful to think about how these statements behave
      across two interpretive models:</p>
      <ul>
      <li><strong>M<sub>phys</sub></strong>: Physical/literal
      interpretation (common sense, ordinary meaning)</li>
      <li><strong>M<sub>interp</sub></strong>: Creative interpretation
      (metaphor, allegory, other figurative readings)</li>
      </ul>
      <!-- The tension between these models reveals what makes certain utterances feel "extra-ordinary." -->
      <h3 id="examples-and-analysis">Examples and Analysis</h3>
      <table>
      <colgroup>
      <col style="width: 22%" />
      <col style="width: 40%" />
      <col style="width: 37%" />
      </colgroup>
      <thead>
      <tr>
      <th>Passage</th>
      <th>Formal Notation</th>
      <th>Plain English</th>
      </tr>
      </thead>
      <tbody>
      <tr>
      <td><em>“Two distincts, division none”</em></td>
      <td>M<sub>phys</sub> ⊨ Distinct(a,b)
      <strong>and</strong><br>M<sub>interp</sub> ⊨ ¬Distinct(a,b)</td>
      <td>Two bodies, one soul</td>
      </tr>
      <tr>
      <td><em>“Hearts remote, yet not asunder”</em></td>
      <td>M<sub>phys</sub> ⊨ Remote(a,b)
      <strong>and</strong><br>M<sub>interp</sub> ⊨ ¬Remote(a,b)</td>
      <td>Spatially apart, spiritually united</td>
      </tr>
      <tr>
      <td><em>“Hot ice / wondrous strange snow”</em><a href="#fn1"
      class="footnote-ref" id="fnref1"
      role="doc-noteref"><sup>1</sup></a></td>
      <td>M<sub>phys</sub> ⊨ ¬(Ice ∧ Hot)
      <strong>and</strong><br>M<sub>interp</sub> ⊨ (Ice ∧ Hot)</td>
      <td>Physically impossible, imaginatively possible</td>
      </tr>
      <tr>
      <td><em>“A cage went in search of a bird”</em></td>
      <td>M<sub>phys</sub> ⊨ ¬Animate(cage) ∧ Search(e, cage, bird) ⇒
      ⊥<br><br>M<sub>interp</sub> ⊨ Search(e, oppression, freedom)</td>
      <td>Cages dont search (type clash)<br><br> metaphorically,
      oppression pursues freedom.</td>
      </tr>
      </tbody>
      </table>
      <h3 id="core-characteristics">Core Characteristics</h3>
      <p>These literary examples share a unifying feature: they present
      a <strong>literal semantic failure</strong> in one domain that
      creates insightful or profound resonance in another domain
      (metaphorical, allegorical, or abstract).</p>
      <p>From the examples above we can <em>loosely group</em> these
      failures into three heuristic patterns:</p>
      <p><span class="math display">\[
      \text{ExO}(\varphi)\; \approx\; \text{MC}(\varphi)\; \lor\;
      \text{MP}(\varphi)\; \lor\; \text{TC}(\varphi)
      \]</span></p>
      <p>Where</p>
      <table>
      <colgroup>
      <col style="width: 26%" />
      <col style="width: 41%" />
      <col style="width: 32%" />
      </colgroup>
      <thead>
      <tr>
      <th>Pattern</th>
      <th>Formal Sketch</th>
      <th>Intuition</th>
      </tr>
      </thead>
      <tbody>
      <tr>
      <td>Modal Clash <strong>(MC)</strong></td>
      <td>M<sub>phys</sub> ⊨ ¬φ <strong>and</strong> M<sub>interp</sub>
      ⊨ φ</td>
      <td>Statement fails in physical model but holds in interpretive
      model</td>
      </tr>
      <tr>
      <td>Modal Projection <strong>(MP)</strong></td>
      <td>M<sub>phys</sub> ⊭ φ <strong>but</strong> M<sub>interp</sub>
      renders φ conceivable</td>
      <td>Physical world disallows φ; imagination projects consistent
      scenario</td>
      </tr>
      <tr>
      <td>Type Clash <strong>(TC)</strong></td>
      <td>φ forces type contradiction in M<sub>phys</sub></td>
      <td>Category mismatch (e.g., animate actions for inanimate
      objects) resolved through reinterpretation</td>
      </tr>
      </tbody>
      </table>
      <h3 id="scope-and-purpose">Scope and Purpose</h3>
      <p>The logic sketch is strictly exploratory. It shows how an
      expression can fracture under a literal reading yet resolve in an
      imaginative one, and it supplies shorthand—MC, MP, TC—for that
      move. Making the break explicit clarifies how objectives rooted in
      the distributional hypothesis e.g. next-token prediction and RLHF
      tuned for coherence could steer models away from ExO language. If
      we want systems that embrace deliberate, meaningful rule-bending,
      we’ll need benchmarks that reward it.</p>
      <h2 id="why-might-current-ai-struggle-here">Why Might Current AI
      Struggle Here?</h2>
      <p>Current language models face several systematic barriers to
      producing ExO language; at this point many of these are my own
      speculation or fan theory than concrete fact, but nevertheless
      here they are:</p>
      <p><strong>Data Scarcity in Pretraining</strong>: Though profound
      literature exists in pretraining corpora (Google Books, etc.),
      it’s statistically underrepresented. By definition, novel writing
      is rare, and easily-licensed conventional text dominates the
      training mix. Even within Pulitzer Prize winning articles/books
      etc the instances of truly profound prose/ExO language (as
      impactful as they may be) are few and far between.</p>
      <p><strong>Objective Mismatch</strong>: From a causal language
      modeling perspective, next token prediction is less about encoding
      the abstract concepts or deep intentionality these examples are
      made up of and more so about emulation of style and prose. At this
      phase models learn to reproduce surface features without encoding
      the abstract concepts that necessarily drive literary innovation.
      Even though large causal models like GPT-3 begin to exhibit some
      few-shot behavior with sufficient examples, it seems unlikely that
      the causal training paradigm alone gets us the reasoning necessary
      for truly novel language.</p>
      <p><strong>Task Absence During Fine-tuning</strong>: When models
      are optimized for instruction following, there’s likely an absence
      of tasks that push them to not just learn ExO behavior, but more
      importantly exhibit it. The training emphasizes practical
      capabilities over creative linguistic reasoning. Though literary
      analysis and reading comprehension are a big part of this phase
      they are somewhat distinct from the task of exhibiting and
      producing novel prose. In short, there are more analyses of great
      works than great works, and the reading comprehension/literary
      analysis task itself aligns more intuitively with how we quantify
      intelligence in school.</p>
      <p><strong>RLHF Optimization Pressure</strong>: This one is fun to
      think about. From a preference learning perspective, I doubt
      anyone wants to do full-blown Harold Bloom literary analysis to
      rate model outputs. Most annotators would favor accessible,
      Wikipedia-style entries over Joycean explorations of any topic.
      This optimization pressure likely eliminates whatever literary
      capabilities emerge during pretraining.</p>
      <p><strong>The Deeper Issue: Fluid Literary Intelligence</strong>:
      The more I examine instances of impactful prose packed with
      intentionality and metaphysical depth, the more convinced I am
      that modeling such language requires what I’d call fluid literary
      intelligence. This goes beyond pattern matching toward adaptive
      generalization on out-of-distribution linguistic tasks.</p>
      <p><strong>Missing Benchmarks</strong>: This leads to deeper
      questions: What constitutes literary novelty computationally? Why
      are there no benchmarks on par with ARC that touch this axis of
      intelligence? Current reasoning evaluation has heavily favored
      verifiable tasks (coding, math) over creative reasoning.</p>
      <p><strong>There is Hope</strong>: Even if this does require some
      deeper literary understanding, if we had 20 Harold Blooms doing
      RLHF or composing benchmarks of curated ExO instances, I believe
      we could optimize models toward this intelligence. Reinforcement
      learning scales. If we went from GPT-3 to ChatGPT with thousands
      of samples, maybe we need just a handful of literary experts.
      Additionaly, this approach could even generalize to other creative
      domains.</p>
      <!-- This is more of a fan theory at this point but it feels like examples of profound language may have surfaced in the models pretraining google books though by definition of novel writing it is likely under represented, additionally from a causal language model base training perspective this is less about encoding the abstract concepts or deep intentionality these examples are made up of and more so about emulation of style and prose at this point in the training. Sure larger models like GPT-3 especially with sufficient examples of this type of text may begin to exhibit some few shot behavior or ability to encode more abstract concepts about this sort of language, but overall I would be surprised if the casual base training paradigm gets us the level of reasoning and intelligence necessary to truly exhibit novel prose. 

      As the models are further optimized on higher level tasks such as instruction following there is probably an absence of task types that push the model to learn this behavior and to be quite frankly from a later RLHF perspective I doubt anyone wants to do a full blown Harold bloom literary analysis of the models output to give a preference rating so I wouldnt be surprised if this step as well beats any sort of literary device capabilities out of the model. In short I dont think many people would favor a Joycean take on XYZ topic over an accessible and informative wikipedia style entry on the matter. Anyway this is all hearsay. 

      The more I examine instances of impactful prose e.g. utterances packed with intentionality and metaphysical depth and try to formally capture their distinctive features, the more convinced I become that modeling such language necessitates a type of fluid literary intelligence. Ultimately, this exploration leads to deeper epistemic questions: what precisely constitutes literary novelty, and how can we recognize and evaluate it computationally, and lastly are there no benchmarks on par with ARC that touch on this axis of intelligence? 

      Also, if we had 20 Harold blooms doing RLHF or composing benchmarks made up of curated instances of ExO language then I truly believe we could optimize models to exhibit this type of intelligence. And RL scales if we got from GPT3 to ChatGPT with 10,000 samples maybe we can just have a handful of Harold Bloom for models. Also could this not generalize to other creative tasks as well? AND historically I believe reasoning tasks/benchmarks have too heavily focused on verifiable tasks such as coding and mathematical reasoning.  -->
      <h2 id="key-readings">Key Readings</h2>
      <p>These papers and essays collectively help explore
      <strong>extra‑ordinary (ExO) language</strong>:
      controllable‑generation techniques expose rare linguistic traces,
      RLHF studies detail how reward shaping affects diversity,
      Chollet’s work addresses fluid intelligence and
      out‑of‑distribution generalization, and the SEP entries offer
      foundational perspectives on metaphor and contradiction—concepts
      central to creativity and nuanced language use.</p>
      <h3 id="controllable-generation">Controllable Generation</h3>
      <ul>
      <li><strong>ActAdd</strong> — <a
      href="https://arxiv.org/pdf/2308.10248">PDF</a></li>
      <li><strong>Contrastive Activation Steering</strong> — <a
      href="https://arxiv.org/pdf/2312.06681">PDF</a></li>
      </ul>
      <h3
      id="rlhf-on-mode-collapse-output-diversity">RLHF on Mode Collapse &amp; Output Diversity</h3>
      <ul>
      <li><strong>Effects of RLHF on Diversity &amp; Generalization</strong>
      — <a href="https://arxiv.org/pdf/2310.06452">PDF</a></li>
      <li><strong>RLHF Effects on Conceptual Diversity</strong> — <a
      href="https://aclanthology.org/2025.naacl-long.561.pdf">PDF</a></li>
      </ul>
      <h3 id="fluid-intelligence">Fluid Intelligence</h3>
      <ul>
      <li><strong>On the Measure of Intelligence</strong> — <a
      href="https://arxiv.org/abs/1911.01547">PDF</a></li>
      </ul>
      <h3
      id="philosophy-of-language-logic">Philosophy of Language &amp; Logic</h3>
      <ul>
      <li><strong>Metaphor</strong>
      (Stanford Encyclopedia of Philosophy) — <a
      href="https://plato.stanford.edu/entries/metaphor/">https://plato.stanford.edu/entries/metaphor/</a></li>
      <li><strong>Contradiction</strong>
      (Stanford Encyclopedia of Philosophy) — <a
      href="https://plato.stanford.edu/entries/contradiction/">https://plato.stanford.edu/entries/contradiction/</a></li>
      </ul>
      <!-- - [Classifier-based guidance for discrete diffusion](https://arxiv.org/pdf/2412.10193)  
      - [TRACE](https://arxiv.org/pdf/2504.18535)  
      - [Constrained Generation (Ctrl-G)](https://arxiv.org/pdf/2406.13892)   -->
      <h2 id="open-problems">Open Problems</h2>
      <p><strong>Empirical Approach</strong>: Can we just crank up the
      temperature and RLHF against literary critics? Is the solution as
      simple as generating more varied outputs and having 20 Harold
      Blooms rank them? Or does this require deeper architectural
      changes?</p>
      <p><strong>Rules vs. Intuition</strong>: Do models need to deeply
      formalize the rules of language to meaningfully break them? Or can
      expert preference data teach the patterns directly without
      explicit rule-learning? This gets at whether ExO generation is
      about systematic reasoning or learned aesthetic judgment.</p>
      <p><strong>Sample Efficiency</strong>: How many expert annotations
      would we actually need? If RLHF worked with 10K of samples for
      ChatGPT, maybe we only need hundreds of expert literary judgments
      to see significant improvement in creative output.</p>
      <p><strong>A broken clock is right twice a day</strong>: Is there
      a meaningful difference between “turning up randomness and
      filtering with experts” versus “genuine creative intelligence”?
      Could high-temperature generation coupled with expert filtering
      approximate the cognitive processes behind ExO language?</p>
      <p><strong>Expert Agreement:</strong> This one is common in
      business problems. Would literary critics even agree on what
      constitutes good ExO language? The subjectivity of literary
      judgment might make this approach messier than mathematical
      reasoning tasks.</p>
      <!-- discuss francios chollets reliability rating as condition for measuring xyz -->
      <p><strong>Socialogical Influence</strong>: How do we account for
      the way social and historical contexts shape judgments of novelty
      and creativity and is it a moving target?</p>
      <p>Novelty and creativity are often historically and socially
      situated. A good deal of what constitutes creatvity and novelty is
      dependent on the historical context in which artistic expressions
      are judged. Citizen Kane, for example, is often cited as one of
      the greatest films of all time due to its innovative
      cinematography and storytelling. However, the cinematic
      innovations that define this film, such as Toland’s use of depth
      of field, is now a staple in most introductory film courses.
      Fashion often follows a similar arc, innovative and fresh designs
      that mark the runway one season saturate the shelves of
      fast-fashion retailers the next.</p>
      <p>Though judgements about creativity and artistic merit are
      heavily influenced by the social and historical factors there is
      still a sense in which great works are able to stand the test of
      time. When evaluating creative intelligence, we must consider how
      social and historical contexts shape our aesthetic judgments and
      distinguish between those that are fleeting and those that
      endure.</p>
      <p><strong>Generalization Limits</strong>: If we optimize models
      toward specific critic preferences, do we get genuine creative
      capability or just better mimicry of those critics’ tastes? I
      think of Wittgensteins example of mimicry and rule following. A
      pupil is learning a geometric series: The pupil has been tested on
      examples of counting by +2 up to 1000. The pupil is then asked to
      continue the task on numbers above 1000 and then writes 1000,
      1004, 1008, 1012. The pupil claims they have been following the
      rule all along: “Up to 1000 I add 2; from 1000 onward I add 4.”
      Every step the pupil took in training was perfectly compatible
      with this alternative rule. Most intelligence tasks are about
      fluid and adaptive generalization.</p>
      <!-- "measuring skill at any given task falls short of measuring intelligence, because skill is heavily modulated by prior knowledge and experience" -->
      <!-- As Wittgenstein states in PI "Must I understand an order before I can act on it? - Certainly, otherwise you wouldn't know what you had to do! - But from knowing to doing is surely a further step!" -->
      <!-- 
      A pupil is learning a geometric series the pupil has been tested on examples up to 1000 then they get the pupil to continue the series (+2) he writes 1000, 1004, 1008, 1012. The pupil claims he has been following the rule all along: “Up to 1000 I add 2; from 1000 onward I add 4.” Every step he took in training was perfectly compatible with this alternative rule. I think this relates to a deeper question posed by arc dataset and apple paper  -->
      <h2 id="closing-thoughts">Closing Thoughts</h2>
      <p>Just because models can exhibit surprisal or violate semantic
      expectations doesn’t always mean they possess the ability to do so
      meaningfully. Ultimately, the goal is to understand whether
      machines can develop the kind of flexible, creative intelligence
      that ExO language represents—and to build evaluation frameworks
      that recognize this intelligence when it emerges. In short, we
      need benchmarks that reward “wondrous strange snow.”</p>
      <!-- 
      Ultimately, the hope is to improve generation so we can guide it toward extra-ordinary usage, language that is *“wondrous strange snow.”* -->
      <hr />
      <p><em>Shout-out to my good friend Joshua for the stimulating
      convo and amazing <strong>Midsummer</strong> example. And
      shout-out to Henry too for the great convos on AGI/ARC and
      thoughts on diffusion-based and RL approaches. And last but not
      least shoutout to Noel for her core contributions on aesthetics
      and philosophical insights on creativity and intelligence</em></p>
      <section id="footnotes"
      class="footnotes footnotes-end-of-document" role="doc-endnotes">
      <hr />
      <ol>
      <li id="fn1"><p><em>Theseus sets up an open contradiction
      <strong>hot</strong> + <strong>ice</strong> only to “resolve” it
      with the sneering flourish “wondrous strange snow.”<br />
      The oxymoron stays physically impossible, but the new name lets
      the audience picture it for a moment as an imaginable
      marvel.<br />
      I think this imaginative license would still make it a
      Modal-Projection (MP).</em><a href="#fnref1" class="footnote-back"
      role="doc-backlink">↩︎</a></p></li>
      </ol>
      </section>
    </article>
  </main>

  <!-- article JS (dark mode only) -->
  <script defer src="../../assets/js/article.js"></script>
</body>
</html>