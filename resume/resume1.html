<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Collins Westnedge – Resume</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <style>
  body {
    max-width: 700px;
    margin: 30px auto;
    padding: 0 20px;
    line-height: 1.5;
    font-size: 11pt;
  }
  
  h1 {
    font-size: 17pt;
    text-align: center;
    letter-spacing: 4px;
    margin-bottom: 12px;
  }
  
  h2 {
    font-size: 11.5pt;
    border-top: 2px solid black;
    border-bottom: 1px solid black;
    padding: 4px 0;
    margin: 18px 0 10px;
    letter-spacing: 2px;
  }
  
  a {
    color: black;
  }
  
  ul {
    margin-left: 28px;
    margin-top: 6px;
    margin-bottom: 12px;
  }
  
  li {
    margin-bottom: 5px;
  }
  
  .header-info {
    text-align: center;
    margin-bottom: 16px;
    font-size: 9.5pt;
  }
  
  .position {
    margin-bottom: 6px;
  }
  
  .company {
    font-weight: bold;
  }
  
  .role {
    font-size: 10pt;
  }
</style>

</head>
<body>

<h1>COLLINS WESTNEDGE</h1>
<div class="header-info">
  Chicago, IL &nbsp;|&nbsp;
  <a href="mailto:cwestnedge@gmail.com">cwestnedge@gmail.com</a> &nbsp;|&nbsp;
  <a href="https://www.linkedin.com/in/collins-westnedge/">LinkedIn</a> &nbsp;|&nbsp;
  <a href="https://donkeyanaphora.github.io">Website</a> &nbsp;|&nbsp;
  <a href="https://github.com/donkeyanaphora">GitHub</a> &nbsp;|&nbsp;
  <a href="https://huggingface.co/cwestnedge">Hugging Face</a>
</div>

<h2>SKILLS</h2>
<p><strong>Programming:</strong> Python (PyTorch, Transformers, NumPy, pandas, scikit-learn), SQL, Git</p>
<p><strong>LLM/NLP:</strong> RAG, prompt engineering, fine-tuning (mixed precision, grad accumulation), shallow fusion for ASR, activation steering, debiasing, contrastive learning</p>
<p><strong>MLOps & Data:</strong> Experiment design & permutation tests, calibration, distributed training, MLflow, Databricks/Spark, Azure (Cognitive Search, Document Intelligence), Kubernetes, Hugging Face Hub</p>

<h2>EXPERIENCE</h2>
<div class="position">
  <span class="company">Northwestern Mutual</span> – Data Science & Analytics<br />
  <span class="role">Senior Data Scientist (2022–Present) &nbsp;|&nbsp; Data Scientist (2021–2022)</span>
</div>
<ul>
  <li><strong>Led data-science efforts</strong> for a CSR-facing RAG platform; designed & implemented automated evaluation reducing A/B cycles from ~30 days to <strong>7 minutes</strong>; adopted across CSR org (~700 users)</li> 
  <li><strong>Unlocked enterprise open source access</strong> by partnering with risk/security and documenting guardrails; delivered Whisper ASR pipeline with <strong>95% cost reduction</strong> vs AWS Transcribe and <strong>30% relative WER improvement</strong> over vendor</li>
  <li><strong>Engineered</strong> a multi-stage LLM workflow for regulatory checks (risk tolerance & consent) with human-in-the-loop validation; <strong>saved 200+ hours annually</strong> while meeting audit requirements</li>
  <li><strong>Sponsored & advised</strong> InfoNCE fine-tuning (contrastive + domain adaptation); project owner achieved a <strong>70%</strong> reduction in vector storage</li>
  <li><strong>Research Subcommittee Member</strong> (2023–Present): Review ML/AI grants, guide experimental design, deliver workshops on ML/AI topics</li>
</ul>

<h2>SELECTED PROJECTS</h2>
<div class="position">
  <span class="company">Medical Speech Recognition via Shallow Fusion</span> – <a href="https://github.com/donkeyanaphora/SHALLOW_FUSION">GitHub</a>
</div>
<ul>
  <li><strong>Implemented</strong> shallow fusion integrating Whisper ASR with domain-adapted GPT-2; achieved an <strong>8.5% relative WER reduction</strong> (p = 0.012) on medical speech</li>
  <li><strong>Built</strong> evaluation framework with medical terminology normalization and permutation-based significance testing</li>
</ul>

<div class="position">
  <span class="company">GPT-2 Domain Adaptation</span> – <a href="https://huggingface.co/cwestnedge">Hugging Face</a>
</div>
<ul>
  <li><strong>Fine-tuned</strong> GPT-2 on 3.6B PubMed tokens using mixed precision (FP16), gradient accumulation (128 effective batch size), and fault-tolerant checkpointing</li>
</ul>

<h2>EDUCATION</h2>
<div class="position">
  <span class="company">University of Chicago</span> – B.A., Philosophy (2018) &nbsp;|&nbsp; Relevant coursework: Logic; Probability and Statistics; Dynamic Semantics
</div>

<div class="position">
  <span class="company">University of Wisconsin–Milwaukee</span> – Mathematics Coursework (2024–Present) &nbsp;|&nbsp; Completed: Linear Algebra; In progress: Calculus III
</div>

</body>
</html>