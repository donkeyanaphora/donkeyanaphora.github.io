<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Extra-Ordinary Language - Collins Westnedge</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no, viewport-fit=cover">
  
  <!-- Mobile app settings -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <!-- SEO essentials -->
  <meta name="google-site-verification" content="hmW81pKLkPLJXY0kFe-I1vNXno-xD9XbEWyZyGfz-SA" />
  <meta name="description" content="An exploration of literary and
creative intelligence and things I wish language models did better.">
  <meta name="author" content="Collins Westnedge">
  <link rel="canonical" href="https://donkeyanaphora.github.io/articles/article3/">
  
  <!-- Hide drafts from search engines -->
  

  <!-- Site look & feel -->
  <link rel="stylesheet" href="../../assets/css/main.css"/>
  <link rel="stylesheet" href="../../assets/css/article.css"/>
  
  <!-- Favicons -->
  <link rel="apple-touch-icon" sizes="180x180" href="../../favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="../../favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../../favicon/favicon-16x16.png">
  <link rel="manifest" href="../../favicon/site.webmanifest">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://donkeyanaphora.github.io/articles/article3/">
  <meta property="og:title" content="Extra-Ordinary Language">
  <meta property="og:description" content="An exploration of literary
and creative intelligence and things I wish language models did
better.">
  <meta property="og:image" content="https://donkeyanaphora.github.io/assets/images/thumbnail.png">
  <meta property="og:site_name" content="The Latent Realm">
  <meta property="article:author" content="Collins Westnedge">
  <meta property="article:published_time" content="2025-07-02">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:url" content="https://donkeyanaphora.github.io/articles/article3/">
  <meta name="twitter:title" content="Extra-Ordinary Language">
  <meta name="twitter:description" content="An exploration of literary
and creative intelligence and things I wish language models did
better.">
  <meta name="twitter:image" content="https://donkeyanaphora.github.io/assets/images/thumbnail.png">

  <!-- MathJax config -->
  <!-- <script>
    window.MathJax = {
      tex:   { displayIndent: '0em',  displayAlign: 'center' },
      chtml: { mtextFont: 'Times' }
    };
  </script> -->
  
  <script>
    window.MathJax = {
      tex: {},  // Empty is fine
      chtml: { 
        mtextFont: 'Times',
        displayAlign: 'center',    // ‚úÖ Moved here
        displayIndent: '0em'       // ‚úÖ Moved here
      }
    };
  </script>
  <!-- MathJax -->
  <script defer id="MathJax-script"
          src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js">
  </script>
</head>

<body class="article">
  <!-- floating buttons -->
  <button id="menuBtn" class="float-btn" aria-label="Open menu">üß∞</button>
  <button class="float-btn back-btn" onclick="window.location.href='../../'" aria-label="Back to home">üè°</button>
  <button id="toggleDark" class="float-btn" aria-label="Toggle dark mode">üåô</button>

  <!-- Markdown content -->
  <main class="content">
    <article class="markdown-body">
      <h1 id="extra-ordinary-language">üé≠ Extra-Ordinary Language</h1>
      <p><strong>COLLINS WESTNEDGE</strong><br />
      <em>JULY 2, 2025</em></p>
      <h2 id="introduction">Introduction</h2>
      <p>I‚Äôve been thinking about a conversation I had with a former
      colleague about language that defies ordinary usage. More
      specifically expressions that violate the <a
      href="https://en.wikipedia.org/wiki/Distributional_semantics">distributional
      hypothesis</a> of language and yet carry high degrees of
      intentionality and depth.</p>
      <p>When Kafka wrote ‚ÄúA cage went in search of a bird,‚Äù he created
      something that on the surface seems impossible and yet expresses a
      profound and insidious truth. Current AI systems, for all their
      linguistic sophistication, rarely produce such language. They
      excel at coherent, informative prose but struggle with the kind of
      intentional violations that define great literature.</p>
      <p>In this post, I‚Äôm dog-earing these thoughts to revisit later.
      The aim here is to understand what makes these expressions work
      and more critically, the implications this has on how we measure
      and evaluate model intelligence.</p>
      <!-- Along the way, I'll attempt some preliminary formalizations and speculate about why current AI systems struggle with this capacity. -->
      <h2 id="literary-examples">Literary Examples</h2>
      <blockquote>
      <p>So they lov‚Äôd, as love in twain<br />
      Had the essence but in one;<br />
      Two distincts, division none:<br />
      Number there in love was slain.</p>
      <p>Hearts remote, yet not asunder;<br />
      Distance and no space was seen<br />
      Twixt this Turtle and his queen</p>
      <p>‚Äî <em>Shakespeare, <strong>The Phoenix and the
      Turtle</strong></em></p>
      </blockquote>
      <blockquote>
      <p>A cage went in search of a bird.</p>
      <p>‚Äî <em>Kafka, <strong>Aphorisms</strong></em></p>
      </blockquote>
      <blockquote>
      <p>I can‚Äôt go on. I‚Äôll go on.</p>
      <p>‚Äî <em>Beckett, <strong>The Unnamable</strong></em></p>
      </blockquote>
      <blockquote>
      <p>Merry and tragical! Tedious and brief!<br />
      That is, hot ice and wondrous strange snow.<br />
      How shall we find the concord of this discord?</p>
      <p>‚Äî <em>Shakespeare, <strong>A Midsummer Night‚Äôs
      Dream</strong></em> <a href="#fn1" class="footnote-ref"
      id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
      </blockquote>
      <h3 id="core-characteristics">Core Characteristics</h3>
      <p>Because of their intentionality and depth I‚Äôm going to call
      these violations of ‚Äúordinary use‚Äù <strong>extra-ordinary
      use</strong> or <strong>ExO language</strong>. They don‚Äôt obscure
      meaning but instead elucidate by way of contradiction or a
      violation of expectations.</p>
      <p>These literary examples share a unifying feature: they present
      a <strong>literal semantic failure</strong> in one domain that
      creates insightful or profound resonance in another domain
      (metaphorical, allegorical, or abstract).</p>
      <p>As DFW said ‚Äúwe all know there‚Äôs no quicker way to empty a joke
      of its particular magic than to explain it‚Äù and the same is true
      for figurative language. However, at the risk of literary
      blasphemy here is one way to illustrate the ways in which these
      expressions <em>may</em> resolve through a figurative
      interpretation:</p>
      <ul>
      <li>‚ÄúTwo distincts, division none‚Äù - two bodies, one soul</li>
      <li>‚ÄúA cage went in search of a bird‚Äù - oppression seeks
      freedom</li>
      <li>‚ÄúI can‚Äôt go on, I‚Äôll go on‚Äù - continuation is not a choice,
      it‚Äôs compulsory</li>
      </ul>
      <p>In each case, the reader encounters a jarring violation of
      expectation that is only resolved through a figurative
      reinterpretation:</p>
      <ul>
      <li>‚ü¶œÜ‚üß<sub>lit</sub> = ‚ä• ; ‚ü¶œÜ‚üß<sub>fig</sub> = œà.</li>
      </ul>
      <p>Here, ‚ü¶œÜ‚üß denotes the interpretation of expression œÜ, ‚ä•
      indicates contradiction, and œà the emergent or resolved
      meaning.</p>
      <p>Ultimately, these examples illustrate how expressions can
      fracture under a literal reading yet resolve in an imaginative
      one. Making that fracture or violation explicit clarifies how
      objectives rooted in the distributional hypothesis e.g.¬†next-token
      prediction or RLHF tuned for coherence and readability could steer
      models away from ExO language. If we want systems that embrace
      deliberate, meaningful rule-bending, we‚Äôll need benchmarks that
      more actively reward it.</p>
      <h2 id="why-might-current-ai-struggle-here">Why Might Current AI
      Struggle Here?</h2>
      <p>Current language models face several systematic barriers to
      producing ExO language; at this point many of these are my own
      thoughts or fan theory rather than concrete fact, but nevertheless
      here they are:</p>
      <p><strong>Data Scarcity in Pretraining</strong>: Though profound
      literature exists in pretraining corpora (Google Books, etc.),
      it‚Äôs statistically underrepresented. By definition, novel writing
      is rare, and easily-licensed conventional text dominates the
      training mix. Even within Pulitzer Prize winning articles/books
      etc the instances of truly profound prose/ExO language (as
      impactful as they may be) are few and far between.</p>
      <p><strong>Objective Mismatch</strong>: From a causal language
      modeling perspective, next token prediction is less about encoding
      the abstract concepts or deep intentionality these examples are
      made up of and more so about emulation of style and prose. At this
      phase models learn to reproduce surface features without encoding
      the abstract concepts that necessarily drive literary innovation.
      Even though large causal models like GPT-3 begin to exhibit some
      few-shot behavior with sufficient examples, it seems unlikely that
      the causal training paradigm alone gets us the abstract
      associative power necessary for truly novel language.</p>
      <p><strong>Task Absence During Fine-tuning</strong>: When models
      are optimized for instruction following, there‚Äôs likely an absence
      of tasks that push them to not just learn ExO behavior, but more
      importantly exhibit it. The training emphasizes practical
      capabilities over creative linguistic reasoning. Though literary
      analysis and reading comprehension are a big part of this phase
      they are somewhat distinct from the task of exhibiting and
      producing novel prose. In short, there are more analyses of great
      works than great works, and the reading comprehension/literary
      analysis task itself aligns more intuitively with how we quantify
      intelligence in school.</p>
      <p><strong>RLHF Optimization Pressure</strong>: This one is fun to
      think about. From a preference learning perspective, I doubt
      anyone wants to do full-blown Harold Bloom literary analysis to
      rate model outputs. Most annotators would favor accessible,
      Wikipedia-style entries over Joycean explorations of any topic.
      This optimization pressure likely eliminates whatever literary
      capabilities emerge during pretraining. There are also many
      studies that suggest RLHF can reduce a model‚Äôs output diversity,
      which can be found in the key readings section further down.</p>
      <p>Studies indicate RLHF improves generalization on benchmark
      tasks at the cost of reduced output diversity, suggesting a
      tradeoff between the two. The interesting case is what happens
      within the set of valid solutions. For tasks that admit many
      correct answers, does RLHF collapse probability mass onto a narrow
      set of conventional solutions? If so, this would work directly
      against fluid intelligence, which, following Chollet, should
      exhibit uniform probability across equally valid outputs while
      suppressing invalid ones. ExO language is precisely the kind of
      output that‚Äôs valid but unconventional: high on the ‚Äúcorrect but
      rare‚Äù end of the distribution, and thus vulnerable to being
      optimized away.</p>
      <p><strong>The Deeper Issue: Fluid Literary Intelligence</strong>:
      The more I examine instances of impactful prose packed with
      intentionality and metaphysical depth, the more convinced I am
      that modeling such language requires what could be called fluid
      literary intelligence. This goes beyond pattern matching toward
      adaptive generalization on out-of-distribution linguistic tasks.
      An ability to traverse distant conceptual pathways, pathways that
      have not surfaced during pretraining. This likely overlaps with
      the intuition that scaling up inference time compute improves
      reasoning models by allowing them to perform a more exhaustive
      grid search of the solution space. However, as far as I can tell
      this strategy mostly applies to verifiable tasks and thus creative
      analogical reasoning in a literary or ExO capacity may remain a
      blindspot.</p>
      <p>In short, ExO language appears to depend on advanced, or at
      least highly creative, analogical reasoning. Its defining feature
      is the construction of meaningful and unexpected connections
      between disparate, and often seemingly contradictory, concepts,
      connections that resist literal validation but nonetheless produce
      insight.</p>
      <p><strong>Missing Benchmarks</strong>: This leads to deeper
      questions: What constitutes literary novelty computationally? Why
      are there no benchmarks on par with ARC that touch this axis of
      intelligence? Current reasoning evaluation has heavily favored
      verifiable tasks (coding, math) over creative reasoning.</p>
      <h2 id="key-readings">Key‚ÄØReadings</h2>
      <p>These papers and essays collectively help explore
      <strong>extra‚Äëordinary‚ÄØ(ExO) language</strong>: RLHF studies
      detail how reward shaping affects diversity, Chollet‚Äôs work
      addresses fluid intelligence and efficient generalization,
      lingustic/philosophical perspectives on metaphor, analogy, and
      contradiction concepts central to creativity and nuanced language
      use.</p>
      <p><strong>RLHF, Mode Collapse &amp; Output Diversity</strong></p>
      <ul>
      <li><a href="https://arxiv.org/abs/2406.05587">Creativity Has Left
      the Chat: The Price of Debiasing Language Models</a> -
      <em>arXiv</em> (2024)</li>
      <li><a
      href="https://openreview.net/pdf?id=PXD3FAVHJT">Understanding the
      Effects of RLHF on LLM Generalisation and Diversity</a> - <em>ICLR
      / OpenReview</em> ‚≠êÔ∏è</li>
      <li><a
      href="https://www.lesswrong.com/posts/t9svvNPNmFf5Qa3TA/mysteries-of-mode-collapse">Mysteries
      of Mode Collapse</a> - <em>LessWrong essay</em></li>
      </ul>
      <p><strong>Exo-Language, Analogical &amp; Fluid
      Reasoning</strong></p>
      <ul>
      <li><p><a href="https://arxiv.org/abs/1911.01547">On the Measure
      of Intelligence</a> - <em>arXiv</em> (Chollet, 2019) ‚≠êÔ∏è</p></li>
      <li><p><a href="https://arxiv.org/abs/2403.11810">Metaphor
      Understanding Challenge Dataset for LLMs</a> - <em>arXiv</em>
      (2024)</p></li>
      <li><p><a
      href="https://aclanthology.org/2025.naacl-long.561.pdf">One fish,
      two fish, but not the whole sea: Alignment reduces language
      models‚Äô conceptual diversity</a> - <em>NAACL 2025</em> ‚≠êÔ∏è</p></li>
      <li><p><a href="https://gwern.net/creative-benchmark">Towards
      Benchmarking LLM Diversity &amp; Creativity</a> -
      <em>Gwern.net</em></p></li>
      </ul>
      <p><strong>Creative Language &amp; Literary Ability in
      LLMs</strong></p>
      <ul>
      <li><a href="https://arxiv.org/abs/2312.03746">Evaluating Large
      Language Model Creativity from a Literary Perspective</a> -
      <em>arXiv</em> (2023)</li>
      <li><a
      href="https://www.nature.com/articles/s41599-025-04999-2">Rethinking
      Literary Creativity in the Digital Age: Human vs.¬†AI
      Playwriting</a> ‚Äî <em>Humanities &amp; Social Sciences
      Communications (Nature)</em> ‚≠êÔ∏è</li>
      <li><a
      href="https://www.sciencedirect.com/science/article/pii/S1871187125001191">Large
      language models show both individual and collective creativity
      comparable to humans</a> - <em>ScienceDirect</em></li>
      </ul>
      <p><strong>Sampling, Diversity &amp; Generation
      Mechanics</strong></p>
      <ul>
      <li><a href="https://arxiv.org/abs/1904.09751">The Curious Case of
      Neural Text Degeneration</a> - <em>arXiv</em> (Holtzman et al.,
      2019) ‚≠êÔ∏è <em>(Introduces nucleus / top-p sampling)</em></li>
      </ul>
      <p><strong>Philosophy of Language &amp; Logic</strong></p>
      <ul>
      <li><a
      href="https://plato.stanford.edu/entries/metaphor/">Metaphor</a> -
      <em>Stanford Encyclopedia of Philosophy</em></li>
      <li><a
      href="https://plato.stanford.edu/entries/contradiction/">Contradiction</a>
      - <em>Stanford Encyclopedia of Philosophy</em></li>
      <li><a
      href="https://en.wikipedia.org/wiki/Catachresis">Catachresis</a> -
      Wikipedia</li>
      <li><a
      href="https://en.wikiversity.org/wiki/Information?utm_source=chatgpt.com">Exformation</a>
      - Wikiversity</li>
      </ul>
      <h2 id="closing-thoughts">Closing Thoughts</h2>
      <p><strong>Sociological Influence</strong>: How do we account for
      the way social and historical contexts shape judgements of novelty
      and creativity and is it a moving target?</p>
      <p>Novelty and creativity are often historically and socially
      situated. A good deal of what constitutes creativity and novelty
      is dependent on the historical context in which artistic
      expressions are judged. Citizen Kane, for example, is often cited
      as one of the greatest films of all time due to its innovative
      cinematography and storytelling. However, the cinematic
      innovations that define this film, such as Toland‚Äôs use of depth
      of field, is now a staple in most introductory film courses.
      Fashion often follows a similar arc, innovative and fresh designs
      that mark the runway one season saturate the shelves of
      fast-fashion retailers the next.</p>
      <p>Though judgements about creativity and artistic merit are
      heavily influenced by the social and historical factors there is
      still a sense in which great works are able to stand the test of
      time. When evaluating creative intelligence, we must consider how
      social and historical contexts shape our aesthetic judgements and
      distinguish between those that are fleeting and those that
      endure.</p>
      <p>Just because models can exhibit surprisal or violate semantic
      expectations doesn‚Äôt always mean they possess the ability to do so
      meaningfully. Ultimately, the goal is to understand whether
      machines can develop the kind of flexible, creative intelligence
      that ExO language represents‚Äîand to build evaluation frameworks
      that recognize this intelligence when it emerges. In short, we
      need benchmarks that reward ‚Äúwondrous strange snow.‚Äù</p>
      <hr />
      <p><em>Shout-out to my good friend Joshua for the stimulating
      convo and amazing <strong>Midsummer</strong> example. And
      shout-out to Henry too for the great convos on AGI/ARC and
      thoughts on diffusion-based and RL approaches. And last but not
      least shoutout to Noel for her core contributions on aesthetics
      and philosophical insights on creativity and intelligence</em></p>
      <!-- [^2]: The table below shows loosely how the literary ExO examples behave across two interpretive models:

      - **M<sub>phys</sub>**: Physical/literal interpretation (common sense, ordinary meaning)
      - **M<sub>interp</sub>**: Creative interpretation (metaphor, allegory, figurative readings)

      | Passage | Pattern | Formal Notation | Plain English |
      |---------|---------|-----------------|---------------|
      | *"Two distincts, division none"* | Modal Clash | M<sub>phys</sub> ‚ä® Distinct(a,b) ‚àß M<sub>interp</sub> ‚ä® ¬¨Distinct(a,b) | Two bodies, one soul |
      | *"Hearts remote, yet not asunder"* | Modal Clash | M<sub>phys</sub> ‚ä® Remote(a,b) ‚àß M<sub>interp</sub> ‚ä® ¬¨Remote(a,b) | Spatially apart, spiritually united |
      | *"Hot ice / wondrous strange snow"* | Modal Projection | M<sub>phys</sub> ‚ä® ¬¨(Ice ‚àß Hot) ‚àß M<sub>interp</sub> ‚ä≠ ¬¨(Ice ‚àß Hot) | Physically impossible, imaginatively conceivable |
      | *"A cage went in search of a bird"* | Type Clash | M<sub>phys</sub>: ¬¨Animate(cage) ‚àß Search(cage, bird) ‚áí ‚ä• | Cages can't search; metaphorically, oppression pursues freedom |
      | *"I can't go on. I'll go on."* | Modal Clash | M<sub>phys</sub> ‚ä® ¬¨Able(x, continue) ‚àß M<sub>interp</sub> ‚ä® Continue(x) | Logical contradiction; existential persistence despite impossibility | -->
      <section id="footnotes"
      class="footnotes footnotes-end-of-document" role="doc-endnotes">
      <hr />
      <ol>
      <li id="fn1"><p><em>Theseus sets up an open contradiction
      <strong>hot</strong> + <strong>ice</strong> only to ‚Äúresolve‚Äù it
      with the sneering flourish ‚Äúwondrous strange snow.‚Äù<br />
      The oxymoron stays physically impossible, but the new name lets
      the audience picture it for a moment as an imaginable
      marvel.<br />
      I think this imaginative license would still make it a
      Modal-Projection (MP).</em><a href="#fnref1" class="footnote-back"
      role="doc-backlink">‚Ü©Ô∏é</a></p></li>
      </ol>
      </section>
    </article>
  </main>

  <!-- article JS (dark mode only) -->
  <script defer src="../../assets/js/article.js"></script>
</body>
</html>